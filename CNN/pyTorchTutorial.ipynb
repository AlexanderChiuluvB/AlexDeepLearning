{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyTorchTutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "SiiuTQFWNXg6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X6n0hmjmAtQ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kOuz-TywNd3l",
        "colab_type": "code",
        "outputId": "76afd17d-b093-483d-f04e-5a6aa3f4e996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "NUM_TRAIN = 49000\n",
        "\n",
        "# The torchvision.transforms package provides tools for preprocessing data\n",
        "# and for performing data augmentation; here we set up a transform to\n",
        "# preprocess the data by subtracting the mean RGB value and dividing by the\n",
        "# standard deviation of each RGB value; we've hardcoded the mean and std.\n",
        "transform = T.Compose([\n",
        "                T.ToTensor(),\n",
        "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "            ])\n",
        "\n",
        "# We set up a Dataset object for each split (train / val / test); Datasets load\n",
        "# training examples one at a time, so we wrap each Dataset in a DataLoader which\n",
        "# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n",
        "# training set into train and val sets by passing a Sampler object to the\n",
        "# DataLoader telling how it should sample from the underlying Dataset.\n",
        "cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
        "                             transform=transform)\n",
        "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
        "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
        "\n",
        "cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
        "                           transform=transform)\n",
        "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
        "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
        "\n",
        "cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, \n",
        "                            transform=transform)\n",
        "loader_test = DataLoader(cifar10_test, batch_size=64)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cs231n/datasets/cifar-10-python.tar.gz\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-1nTACISNui0",
        "colab_type": "code",
        "outputId": "44fb4e3b-5c63-41d8-a057-ec0b66392d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "USE_GPU = True\n",
        "\n",
        "dtype = torch.float32 # we will be using float throughout this tutorial\n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# Constant to control how frequently we print train loss\n",
        "print_every = 100\n",
        "\n",
        "print('using device:', device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xmZewjAbNeEj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "da06db35-103b-4c98-bcb2-960e7369a68b"
      },
      "cell_type": "code",
      "source": [
        "def flatten(x):\n",
        "  N = x.shape[0] #[N,C,H,W]\n",
        "  return x.view(N,-1)  # [N,C*H*W]\n",
        "\n",
        "x =torch.arange(12).view(2,1,3,2)\n",
        "print(x)\n",
        "flatten_x = flatten(x)\n",
        "print(flatten_x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[ 0,  1],\n",
            "          [ 2,  3],\n",
            "          [ 4,  5]]],\n",
            "\n",
            "\n",
            "        [[[ 6,  7],\n",
            "          [ 8,  9],\n",
            "          [10, 11]]]])\n",
            "tensor([[ 0,  1,  2,  3,  4,  5],\n",
            "        [ 6,  7,  8,  9, 10, 11]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MFOO0Y8sNeQE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "bb4da45c-3259-4b13-ab08-ccc056e787f7"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.nn.functional as F\n",
        "def two_layer_fc(x,params):\n",
        "  x = flatten(x)\n",
        "  w1,w2 = params\n",
        "  \n",
        "  x = F.relu(x.mm(w1))\n",
        "  x = x.mm(w2)\n",
        "  return x\n",
        "\n",
        "h = 42\n",
        "x = torch.zeros((64,50),dtype=dtype) # 64 minibatch size\n",
        "w1 = torch.zeros((50,h),dtype=dtype)\n",
        "w2 = torch.zeros((h,10),dtype=dtype)\n",
        "scores = two_layer_fc(x,[w1,w2])\n",
        "print(scores.size())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m9q8QjU8NedA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def three_layer_convnet(x,params):\n",
        "  conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params\n",
        "  scores = None\n",
        "  \n",
        "  conv1 = F.conv2d(x,weight=conv_w1,bias=conv_b1,padding=2)\n",
        "  relu1 = F.relu(conv1)\n",
        "  conv2 = F.conv2d(relu1,weight=conv_w2,bias=conv_b2,padding=1)\n",
        "  relu2 = F.relu(conv2)\n",
        "  relu2_flat = flatten(relu2)\n",
        "  scores = relu2_flat.mm(fc_w)+fc_b\n",
        "  return scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VF_1LU01CFgl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6b19e72a-e0db-4c58-d5a0-4d7fdb7492be"
      },
      "cell_type": "code",
      "source": [
        "def three_layer_convnet_test():\n",
        "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n",
        "\n",
        "    conv_w1 = torch.zeros((6, 3, 5, 5), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n",
        "    conv_b1 = torch.zeros((6,))  # out_channel\n",
        "    conv_w2 = torch.zeros((9, 6, 3, 3), dtype=dtype)  # [out_channel, in_channel, kernel_H, kernel_W]\n",
        "    conv_b2 = torch.zeros((9,))  # out_channel\n",
        "\n",
        "    # you must calculate the shape of the tensor after two conv layers, before the fully-connected layer\n",
        "    fc_w = torch.zeros((9 * 32 * 32, 10))\n",
        "    fc_b = torch.zeros(10)\n",
        "\n",
        "    scores = three_layer_convnet(x, [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b])\n",
        "    print(scores.size())  # you should see [64, 10]\n",
        "three_layer_convnet_test()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mBoekE1RIIRK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "0d176c8a-7a25-49b6-ef98-d93e0de72b18"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def random_weight(shape):\n",
        "    \"\"\"\n",
        "    Create random Tensors for weights; setting requires_grad=True means that we\n",
        "    want to compute gradients for these Tensors during the backward pass.\n",
        "    We use Kaiming normalization: sqrt(2 / fan_in)\n",
        "    \"\"\"\n",
        "    if len(shape) == 2:  # FC weight\n",
        "        fan_in = shape[0]\n",
        "    else:\n",
        "        fan_in = np.prod(shape[1:]) # conv weight [out_channel, in_channel, kH, kW]\n",
        "    # randn is standard normal distribution generator. \n",
        "    w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / fan_in)\n",
        "    w.requires_grad = True\n",
        "    return w\n",
        "\n",
        "def zero_weight(shape):\n",
        "    return torch.zeros(shape, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "# create a weight of shape [3 x 5]\n",
        "# you should see the type `torch.cuda.FloatTensor` if you use GPU. \n",
        "# Otherwise it should be `torch.FloatTensor`\n",
        "random_weight((3, 5))\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.4078, -0.7440,  0.4925, -1.2667, -0.2544],\n",
              "        [-0.2470,  1.1927, -0.0288,  1.3423,  0.1408],\n",
              "        [ 1.2643, -1.5319,  0.1252, -1.2128,  0.6428]], device='cuda:0',\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "lnH0et2LCFqo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def check_accuracy(loader,model,params):\n",
        "  \"\"\"\n",
        "  loader: a dataloader for the data split we want to check\n",
        "  model_fn: a function that performs forward pass\n",
        "  \n",
        "  \"\"\"\n",
        "  \n",
        "  split = 'val' if loader.dataset.train else 'test'\n",
        "  num_correct,num_samples = 0,0\n",
        "  with torch.no_grad():\n",
        "    for x,y in loader:\n",
        "      x = x.to(device=device,dtype=dtype)\n",
        "      y = y.to(device=device,dtype=torch.int64)\n",
        "      scores = model(x,params)\n",
        "      _,preds = scores.max(1)\n",
        "      num_correct += (preds==y).sum()\n",
        "      num_samples += preds.size(0)\n",
        "    acc = float(num_correct)/num_samples\n",
        "    print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tLKxF_R6JVSc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model,params,lr):\n",
        "  for t,(x,y) in enumerate(loader_train):\n",
        "    x = x.to(device = device,dtype=dtype)\n",
        "    y = y.to(device= device,dtype=torch.long)\n",
        "    \n",
        "    scores = model(x,params)\n",
        "    loss = F.cross_entropy(scores,y)\n",
        "    \n",
        "    loss.backward()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      for w in params:\n",
        "        w -= learning_rate * w.grad\n",
        "        \n",
        "        w.grad.zero_()\n",
        "    if t % print_every ==0:\n",
        "      print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
        "      check_accuracy(loader_val, model, params)\n",
        "      print()\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I89r4hSiJawv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "abfd65c2-d758-42f7-9f71-1d84a503e6e8"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "hidden_layer_size = 4000\n",
        "learning_rate = 1e-2\n",
        "\n",
        "w1 = random_weight((3 * 32 * 32, hidden_layer_size))\n",
        "w2 = random_weight((hidden_layer_size, 10))\n",
        "\n",
        "train(two_layer_fc, [w1, w2], learning_rate)\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0, loss = 3.2052\n",
            "Got 156 / 1000 correct (15.60%)\n",
            "\n",
            "Iteration 100, loss = 2.1699\n",
            "Got 363 / 1000 correct (36.30%)\n",
            "\n",
            "Iteration 200, loss = 2.4274\n",
            "Got 294 / 1000 correct (29.40%)\n",
            "\n",
            "Iteration 300, loss = 2.1906\n",
            "Got 386 / 1000 correct (38.60%)\n",
            "\n",
            "Iteration 400, loss = 2.0002\n",
            "Got 409 / 1000 correct (40.90%)\n",
            "\n",
            "Iteration 500, loss = 1.6979\n",
            "Got 385 / 1000 correct (38.50%)\n",
            "\n",
            "Iteration 600, loss = 1.7553\n",
            "Got 418 / 1000 correct (41.80%)\n",
            "\n",
            "Iteration 700, loss = 1.2617\n",
            "Got 434 / 1000 correct (43.40%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aKr5dJdnJa50",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "51acdc55-2e79-4a8f-c106-e50deaa1ce64"
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 3e-3\n",
        "\n",
        "channel_1 = 32\n",
        "channel_2 = 16\n",
        "\n",
        "conv_w1 = None\n",
        "conv_b1 = None\n",
        "conv_w2 = None\n",
        "conv_b2 = None\n",
        "fc_w = None\n",
        "fc_b = None\n",
        "\n",
        "################################################################################\n",
        "# TODO: Initialize the parameters of a three-layer ConvNet.                    #\n",
        "################################################################################\n",
        "conv_w1 = random_weight((channel_1,3,5,5))#[input,output,kh,kw]\n",
        "conv_b1 = zero_weight((channel_1,))\n",
        "conv_w2 = random_weight((channel_2,32,3,3))\n",
        "conv_b2 = zero_weight((channel_2,))\n",
        "fc_w = random_weight((channel_2*32*32,10)) #[input,output]\n",
        "fc_b = zero_weight((10,))\n",
        "\n",
        "################################################################################\n",
        "#                                 END OF YOUR CODE                             #\n",
        "################################################################################\n",
        "\n",
        "params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]\n",
        "train(three_layer_convnet, params, learning_rate)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0, loss = 2.8519\n",
            "Got 101 / 1000 correct (10.10%)\n",
            "\n",
            "Iteration 100, loss = 1.8218\n",
            "Got 342 / 1000 correct (34.20%)\n",
            "\n",
            "Iteration 200, loss = 1.8742\n",
            "Got 374 / 1000 correct (37.40%)\n",
            "\n",
            "Iteration 300, loss = 1.6840\n",
            "Got 405 / 1000 correct (40.50%)\n",
            "\n",
            "Iteration 400, loss = 1.4674\n",
            "Got 429 / 1000 correct (42.90%)\n",
            "\n",
            "Iteration 500, loss = 1.8531\n",
            "Got 449 / 1000 correct (44.90%)\n",
            "\n",
            "Iteration 600, loss = 1.3403\n",
            "Got 443 / 1000 correct (44.30%)\n",
            "\n",
            "Iteration 700, loss = 1.7381\n",
            "Got 462 / 1000 correct (46.20%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PO5kz48NPnjp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "dac40d4f-a5d0-4815-ccc0-0f1ab0d58b09"
      },
      "cell_type": "code",
      "source": [
        "class ThreeLayerConvNet(nn.Module):\n",
        "    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n",
        "        super().__init__()\n",
        "        ########################################################################\n",
        "        # TODO: Set up the layers you need for a three-layer ConvNet with the  #\n",
        "        # architecture defined above.                                          #\n",
        "        ########################################################################\n",
        "        self.conv1 = nn.Conv2d(in_channel,channel_1,kernel_size=5,padding=2,bias=True)\n",
        "        nn.init.kaiming_normal_(self.conv1.weight)\n",
        "        nn.init.constant_(self.conv1.bias,0)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(channel_1,channel_2,kernel_size=3,padding=1,bias=True)\n",
        "        nn.init.kaiming_normal_(self.conv2.weight)\n",
        "        nn.init.constant_(self.conv2.bias,0)\n",
        "        \n",
        "        self.fc = nn.Linear(channel_2*32*32,num_classes)\n",
        "        nn.init.kaiming_normal_(self.fc.weight)\n",
        "        nn.init.constant_(self.fc.bias,0)\n",
        "        \n",
        "        \n",
        "        ########################################################################\n",
        "        #                          END OF YOUR CODE                            #       \n",
        "        ########################################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        scores = None\n",
        "        ########################################################################\n",
        "        # TODO: Implement the forward function for a 3-layer ConvNet. you      #\n",
        "        # should use the layers you defined in __init__ and specify the        #\n",
        "        # connectivity of those layers in forward()                            #\n",
        "        ########################################################################\n",
        "        relu1 = F.relu(self.conv1(x))\n",
        "        relu2 = F.relu(self.conv2(relu1))\n",
        "        scores = self.fc(flatten(relu2))\n",
        "        ########################################################################\n",
        "        #                             END OF YOUR CODE                         #\n",
        "        ########################################################################\n",
        "        return scores\n",
        "\n",
        "\n",
        "def test_ThreeLayerConvNet():\n",
        "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n",
        "    model = ThreeLayerConvNet(in_channel=3, channel_1=12, channel_2=8, num_classes=10)\n",
        "    scores = model(x)\n",
        "    print(scores.size())  # you should see [64, 10]\n",
        "test_ThreeLayerConvNet()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3rkXan30Um7L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def check_accuracy_part34(loader, model):\n",
        "    if loader.dataset.train:\n",
        "        print('Checking accuracy on validation set')\n",
        "    else:\n",
        "        print('Checking accuracy on test set')   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()  # set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "            scores = model(x)\n",
        "            _, preds = scores.max(1)\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_samples += preds.size(0)\n",
        "        acc = float(num_correct) / num_samples\n",
        "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BCCGP6wHUobk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_part34(model, optimizer, epochs=1):\n",
        "    \"\"\"\n",
        "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
        "    \n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "    \n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "    for e in range(epochs):\n",
        "        for t, (x, y) in enumerate(loader_train):\n",
        "            model.train()  # put model to training mode\n",
        "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "            y = y.to(device=device, dtype=torch.long)\n",
        "\n",
        "            scores = model(x)\n",
        "            loss = F.cross_entropy(scores, y)\n",
        "\n",
        "            # Zero out all of the gradients for the variables which the optimizer\n",
        "            # will update.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # This is the backwards pass: compute the gradient of the loss with\n",
        "            # respect to each  parameter of the model.\n",
        "            loss.backward()\n",
        "\n",
        "            # Actually update the parameters of the model using the gradients\n",
        "            # computed by the backwards pass.\n",
        "            optimizer.step()\n",
        "\n",
        "            if t % print_every == 0:\n",
        "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
        "                check_accuracy_part34(loader_val, model)\n",
        "                print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ppqN2hZU2Gj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "727e30e4-9296-4ec5-fe46-af450582debf"
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 3e-3\n",
        "channel_1 = 32\n",
        "channel_2 = 16\n",
        "\n",
        "model = None\n",
        "optimizer = None\n",
        "\n",
        "model = ThreeLayerConvNet(3,channel_1,channel_2,10)\n",
        "optimizer = optim.SGD(model.parameters(),lr=learning_rate)\n",
        "\n",
        "train_part34(model, optimizer)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0, loss = 3.4384\n",
            "Checking accuracy on validation set\n",
            "Got 147 / 1000 correct (14.70)\n",
            "\n",
            "Iteration 100, loss = 1.6623\n",
            "Checking accuracy on validation set\n",
            "Got 351 / 1000 correct (35.10)\n",
            "\n",
            "Iteration 200, loss = 1.8252\n",
            "Checking accuracy on validation set\n",
            "Got 394 / 1000 correct (39.40)\n",
            "\n",
            "Iteration 300, loss = 1.4923\n",
            "Checking accuracy on validation set\n",
            "Got 421 / 1000 correct (42.10)\n",
            "\n",
            "Iteration 400, loss = 1.5491\n",
            "Checking accuracy on validation set\n",
            "Got 439 / 1000 correct (43.90)\n",
            "\n",
            "Iteration 500, loss = 1.5489\n",
            "Checking accuracy on validation set\n",
            "Got 477 / 1000 correct (47.70)\n",
            "\n",
            "Iteration 600, loss = 1.4089\n",
            "Checking accuracy on validation set\n",
            "Got 476 / 1000 correct (47.60)\n",
            "\n",
            "Iteration 700, loss = 1.4539\n",
            "Checking accuracy on validation set\n",
            "Got 488 / 1000 correct (48.80)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EQpO_RD9UomR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Sequential API\n",
        "\n",
        "def kaiming_normal(shape):\n",
        "    \"\"\"\n",
        "    Create random Tensors for weights; setting requires_grad=True means that we\n",
        "    want to compute gradients for these Tensors during the backward pass.\n",
        "    We use Kaiming normalization: sqrt(2 / fan_in)\n",
        "    \"\"\"\n",
        "    if len(shape) == 2:  # FC weight\n",
        "        fan_in = shape[1]  # different from `random_weight()`, as weight for nn.Linear in pytorch is of shape: [out_feature, in_feature]\n",
        "    else:\n",
        "        fan_in = np.prod(shape[1:]) # conv weight [out_channel, in_channel, kH, kW]\n",
        "    # randn is standard normal distribution generator. \n",
        "    w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / fan_in)\n",
        "    w.requires_grad = True\n",
        "    return w\n",
        "\n",
        "def xavier_normal(shape):\n",
        "    \"\"\"\n",
        "    Create random Tensors for weights; setting requires_grad=True means that we\n",
        "    want to compute gradients for these Tensors during the backward pass.\n",
        "    We use Xavier normalization: sqrt(2 / (fan_in + fan_out))\n",
        "    \"\"\"\n",
        "    if len(shape) == 2:  # FC weight\n",
        "        fan_in = shape[1]\n",
        "        fan_out = shape[0]\n",
        "    else:\n",
        "        fan_in = np.prod(shape[1:]) # conv weight [out_channel, in_channel, kH, kW]\n",
        "        fan_out = shape[0] * shape[2] * shape[3]\n",
        "    # randn is standard normal distribution generator. \n",
        "    w = torch.randn(shape, device=device, dtype=dtype) * np.sqrt(2. / (fan_in + fan_out))\n",
        "    w.requires_grad = True\n",
        "    return w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xFJJHE56V6n-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "a7f50d36-196e-4b0b-8e44-93446bbff327"
      },
      "cell_type": "code",
      "source": [
        "channel_1 = 32\n",
        "channel_2 = 16\n",
        "learning_rate = 1e-2\n",
        "\n",
        "model = None\n",
        "optimizer = None\n",
        "\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "  def forward(self,X):\n",
        "    return flatten(X)\n",
        "\n",
        "model = nn.Sequential(\n",
        "\n",
        "  nn.Conv2d(3,channel_1,kernel_size=5,padding=2),\n",
        "  nn.ReLU(),\n",
        "  nn.Conv2d(channel_1,channel_2,kernel_size=3,padding=1),\n",
        "  nn.ReLU(),\n",
        "  Flatten(),\n",
        "  nn.Linear(channel_2*32*32,10),\n",
        ")\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(),lr=learning_rate,momentum=0.9,nesterov=True)\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
        "#         m.weight.data = random_weight(m.weight.size())\n",
        "#         m.weight.data = kaiming_normal(m.weight.size())\n",
        "        m.weight.data = xavier_normal(m.weight.size())\n",
        "        m.bias.data = zero_weight(m.bias.size())\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "################################################################################\n",
        "#                                 END OF YOUR CODE                             \n",
        "################################################################################\n",
        "\n",
        "train_part34(model, optimizer)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0, loss = 2.3894\n",
            "Checking accuracy on validation set\n",
            "Got 113 / 1000 correct (11.30)\n",
            "\n",
            "Iteration 100, loss = 1.4601\n",
            "Checking accuracy on validation set\n",
            "Got 448 / 1000 correct (44.80)\n",
            "\n",
            "Iteration 200, loss = 1.4637\n",
            "Checking accuracy on validation set\n",
            "Got 496 / 1000 correct (49.60)\n",
            "\n",
            "Iteration 300, loss = 1.3498\n",
            "Checking accuracy on validation set\n",
            "Got 529 / 1000 correct (52.90)\n",
            "\n",
            "Iteration 400, loss = 1.1211\n",
            "Checking accuracy on validation set\n",
            "Got 521 / 1000 correct (52.10)\n",
            "\n",
            "Iteration 500, loss = 1.0137\n",
            "Checking accuracy on validation set\n",
            "Got 526 / 1000 correct (52.60)\n",
            "\n",
            "Iteration 600, loss = 1.1234\n",
            "Checking accuracy on validation set\n",
            "Got 568 / 1000 correct (56.80)\n",
            "\n",
            "Iteration 700, loss = 1.1170\n",
            "Checking accuracy on validation set\n",
            "Got 569 / 1000 correct (56.90)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rXN0G2UAV60o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "outputId": "2aaad1b9-2864-4d41-f38b-d469bd45a270"
      },
      "cell_type": "code",
      "source": [
        "layer1 = nn.Sequential(\n",
        "    nn.Conv2d(3,16,kernel_size=5,padding=2),\n",
        "    nn.BatchNorm2d(16),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2)\n",
        ")\n",
        "\n",
        "layer2 = nn.Sequential(\n",
        "    nn.Conv2d(16,32,kernel_size=3,padding=1),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2)\n",
        ")\n",
        "\n",
        "\n",
        "layer3 = nn.Sequential(\n",
        "    nn.Conv2d(32,64,kernel_size=3,padding=1),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2)\n",
        ")\n",
        "\n",
        "layer4 = nn.Sequential(\n",
        "    nn.Conv2d(64,128,kernel_size=3,padding=1),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2)\n",
        ")\n",
        "\n",
        "\n",
        "fc = nn.Linear(128*4,10)\n",
        "\n",
        "model = nn.Sequential(\n",
        "\n",
        "  layer1,\n",
        "  layer2,\n",
        "  layer3,\n",
        "  layer4,\n",
        "  Flatten(),\n",
        "  fc,\n",
        ")\n",
        "\n",
        "learning_rate = 1e-3\n",
        "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
        "print_every = 10000\n",
        "\n",
        "train_part34(model,optimizer,epochs=10\n",
        "            )\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0, loss = 2.3082\n",
            "Checking accuracy on validation set\n",
            "Got 105 / 1000 correct (10.50)\n",
            "\n",
            "Iteration 0, loss = 1.1285\n",
            "Checking accuracy on validation set\n",
            "Got 663 / 1000 correct (66.30)\n",
            "\n",
            "Iteration 0, loss = 0.7189\n",
            "Checking accuracy on validation set\n",
            "Got 706 / 1000 correct (70.60)\n",
            "\n",
            "Iteration 0, loss = 0.6058\n",
            "Checking accuracy on validation set\n",
            "Got 731 / 1000 correct (73.10)\n",
            "\n",
            "Iteration 0, loss = 0.6886\n",
            "Checking accuracy on validation set\n",
            "Got 723 / 1000 correct (72.30)\n",
            "\n",
            "Iteration 0, loss = 0.4477\n",
            "Checking accuracy on validation set\n",
            "Got 725 / 1000 correct (72.50)\n",
            "\n",
            "Iteration 0, loss = 0.4083\n",
            "Checking accuracy on validation set\n",
            "Got 757 / 1000 correct (75.70)\n",
            "\n",
            "Iteration 0, loss = 0.4539\n",
            "Checking accuracy on validation set\n",
            "Got 752 / 1000 correct (75.20)\n",
            "\n",
            "Iteration 0, loss = 0.4746\n",
            "Checking accuracy on validation set\n",
            "Got 761 / 1000 correct (76.10)\n",
            "\n",
            "Iteration 0, loss = 0.2062\n",
            "Checking accuracy on validation set\n",
            "Got 759 / 1000 correct (75.90)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lbuws3tnV6-s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "5e89654a-f2cb-4459-f444-a8fa98279bd7"
      },
      "cell_type": "code",
      "source": [
        "best_model = model\n",
        "check_accuracy_part34(loader_test, best_model)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on test set\n",
            "Got 7509 / 10000 correct (75.09)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z_IwOFH6V7Dl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vKXocndWV7Gn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}