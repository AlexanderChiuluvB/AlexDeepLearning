{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlowVGG.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexanderChiuluvB/AlexDeepLearning/blob/master/TensorFlowVGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7pPseBTxdA1V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "from datetime import datetime\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mmqi1G_fdHz5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv_op(input_op,name,kh,kw,n_out,dh,dw,p):\n",
        "  \"\"\"\n",
        "  kh kw　是卷积核的高和卷积核的宽\n",
        "  dh dw 步长的高和宽\n",
        "  \"\"\"\n",
        "  \n",
        "  n_in = input_op.get_shape()[-1].value\n",
        "  with tf.name_scope(name) as scope:\n",
        "    kernel = tf.get_variable(scope+\"w\",\n",
        "                            shape=[kh,kw,n_in,n_out],dtype=tf.float32,initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
        "    conv = tf.nn.conv2d(input_op,kernel,(1,dh,dw,1),padding='SAME')\n",
        "    bias_init_val = tf.constant(0.0,shape=[n_out],dtype=tf.float32)\n",
        "    biases = tf.Variable(bias_init_val,trainable=True,name='b')\n",
        "    z = tf.nn.bias_add(conv,biases)\n",
        "    \n",
        "    activation = tf.nn.relu(z,name=scope)\n",
        "    p+=[kernel,biases]\n",
        "    \n",
        "    return activation\n",
        "\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TLTC3WBtdH-k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fc_op(input_op,name,n_out,p):\n",
        "  \"\"\"\n",
        "  biases will set to 0.1 to avoid dead neuron\n",
        "  \n",
        "  \"\"\"\n",
        "  \n",
        "  n_in = input_op.get_shape()[-1].value\n",
        "  \n",
        "  with tf.name_scope(name)as scope:\n",
        "    kernel = tf.get_variable(scope+\"w\",shape=[n_in,n_out],dtype=tf.float32,initializer=tf.contrib.layers.xavier_initializer())\n",
        "    biases = tf.Variable(tf.constant(0.1,shape=[n_out],dtype=tf.float32),name='b')\n",
        "    activation = tf.nn.relu_layer(input_op,kernel,biases,name=scope)\n",
        "    p+=[kernel,biases]\n",
        "    return activation\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Hmmc8pCdIBp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mpool_op(input_op,name,kh,kw,dh,dw):\n",
        "  return tf.nn.max_pool(input_op,ksize=[1,kh,kw,1],strides=[1,dh,dw,1],padding='SAME',name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i9QUxSoTgH_R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "VGGNet-16 分为6个部分，前五个部分是卷积网络，最后一段是全连接网络。\n",
        "\n",
        "\"\"\"\n",
        "def inference_op(input_op,keep_prob):\n",
        "  \n",
        "  p = []\n",
        "  \"\"\"\n",
        "  池化层kh,kw=2，输出的图像边长变为原来的１／２，(h-kh)/2+1\n",
        "  然而每层通道数量变为原来的两倍\n",
        "  因此输出的ｔｅｎｓｏｒ的总尺寸会减少一半。\n",
        "  \n",
        "  \"\"\"\n",
        "  \n",
        "  \n",
        "  conv1_1 = conv_op(input_op,name=\"conv1_1\",kh=3,kw=3,n_out=64,dh=1,dw=1,p=p)\n",
        "  conv1_2 = conv_op(conv1_1,name=\"conv1_2\",kh=3,kw=3,n_out=64,dh=1,dw=1,p=p)\n",
        "  pool_1 = mpool_op(conv1_2,name=\"pool_1\",kh=2,kw=2,dw=2,dh=2)\n",
        "  \n",
        "  conv2_1 = conv_op(pool_1,name=\"conv2_1\",kh=3,kw=3,n_out=128,dh=1,dw=1,p=p)\n",
        "  conv2_2 = conv_op(conv2_1,name=\"conv2_2\",kh=3,kw=3,n_out=128,dh=1,dw=1,p=p)\n",
        "  pool_2 = mpool_op(conv2_2,name=\"pool_2\",kh=2,kw=2,dw=2,dh=2)\n",
        "  \n",
        "  \n",
        "  conv3_1 = conv_op(pool_2,name=\"conv3_1\",kh=3,kw=3,n_out=256,dh=1,dw=1,p=p)\n",
        "  conv3_2 = conv_op(conv3_1,name=\"conv3_2\",kh=3,kw=3,n_out=256,dh=1,dw=1,p=p)\n",
        "  conv3_3 = conv_op(conv3_2,name=\"conv3_3\",kh=3,kw=3,n_out=256,dh=1,dw=1,p=p)\n",
        "  pool_3 = mpool_op(conv3_3,name=\"pool_3\",kh=2,kw=2,dw=2,dh=2)\n",
        "  \n",
        "  \n",
        "  conv４_1 = conv_op(pool_３,name=\"conv4_1\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
        "  conv４_2 = conv_op(conv４_1,name=\"conv4_2\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
        "  conv４_3 = conv_op(conv４_2,name=\"conv4_3\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
        "  pool_４ = mpool_op(conv４_3,name=\"pool_4\",kh=2,kw=2,dw=2,dh=2)\n",
        "  \n",
        "  conv5_1 = conv_op(pool_4,name=\"conv4_1\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
        "  conv5_2 = conv_op(conv5_1,name=\"conv4_2\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
        "  conv5_3 = conv_op(conv5_2,name=\"conv4_3\",kh=3,kw=3,n_out=512,dh=1,dw=1,p=p)\n",
        "  pool_5 = mpool_op(conv5_3,name=\"pool_5\",kh=2,kw=2,dw=2,dh=2)\n",
        " \n",
        "  shp = pool_5.get_shape()\n",
        "  flattened_shape = shp[1].value*shp[2].value*shp[3].value\n",
        "  \n",
        "  resh1 = tf.reshape(pool_5,[-1,flattened_shape],name='resh1')\n",
        "  \n",
        "  #dropout layer\n",
        "  \n",
        "  fc6 = fc_op(resh1,name=\"fc6\",n_out=4096,p=p)\n",
        "  fc6_drop = tf.nn.dropout(fc6,keep_prob,name='fc6_drop')\n",
        "  \n",
        "  fc7 = fc_op(fc6,name=\"fc7\",n_out=4096,p=p)\n",
        "  fc7_drop = tf.nn.dropout(fc7,keep_prob,name='fc7_drop')\n",
        "\n",
        "  fc8 = fc_op(fc7,name=\"fc8\",n_out=1000,p=p)\n",
        "  softmax = tf.nn.softmax(fc8)\n",
        "  predictions = tf.argmax(softmax,1)\n",
        "  \n",
        "  return predictions,softmax,fc8,p\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZoPY9vnEkr08",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run():\n",
        "  with tf.Graph().as_default():\n",
        "    image_size = 224\n",
        "    images = tf.Variable(tf.random_normal([batch_size,image_size,image_size,3],dtype=tf.float32,stddev=1e-1))\n",
        "    keep_prob = tf.placeholder(tf.float32)\n",
        "    predictions,softmax,fc8,p = inference_op(images,keep_prob)\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess = tf.Session()\n",
        "    sess.run(init)\n",
        "    \n",
        "    objective  =tf.nn.l2_loss(fc8)\n",
        "    grad = tf.gradients(objective,p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fTTDusNnksHa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "5dd40937-5543-498d-c13a-26d2f3f94658"
      },
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "num_batches=100\n",
        "run()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-14-c88c541c2eb2>:49: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HqP1Dm85gIEp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XAvHAkY7gIII",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}